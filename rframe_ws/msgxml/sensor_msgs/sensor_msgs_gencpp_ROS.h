// 
//  AUTOGENERATED FILE:   do not edit
//
//  Generated by:         yongbo on yongbo-XPS-15-9550, 2017-01-26 15:57:07 -0500
//  From Template/Script: data_templates/ROSTemplate.h.rb
 
/*
  CTA RIGHTS

  This document contains information proprietary to General Dynamics
  Robotic Systems and is not to be reproduced, transmitted, transferred,
  or otherwise used without the express written consent of General
  Dynamics Robotic Systems except as described below.

  GOVERNMENT PURPOSE RIGHTS

  Contract No.:        W911NF-10-2-0016, Articles of Collaboration,
                       Article 5, Intellectual Property
  Contractor Name:     General Dynamics Robotic Systems, Inc. (GDRS)
  Contractor Address:  1231 Tech Court, Westminster, MD  21157

  Expiration Date - None

  Technical data and computer software first created by Member(s) in
  performance of the Agreement will be disclosed to the Government.
  General Dynamics Robotic Systems retains the entire right, title, and
  interest throughout the world to each subject invention subject to the
  provisions of this clause and 37 CFR Part 401, 32 CFR 32.36, and
  34 CFR 34.25. The Government shall have the right to obtain, reproduce,
  publish or otherwise use the work for Government purposes.

  NON-EXCLUSIVE LICENSE TO CONSORTIUM PARTICIPANTS
  Consortium Members and subawardees are defined as 'Participants'
  Under Article 5.3, Participants are granted a nonexclusive, royalty-
  free, non-sublicenseable, non-assignable, license to Consortium
  Intellectual Property for the limited purpose of performing tasks under
  The Cooperative Agreement, for Government purposes only, and to make and
  have the same made solely for such use.

*/

#ifndef _CODEGEN_SENSOR_MSGS_GENCPP_ROS_H_
#define _CODEGEN_SENSOR_MSGS_GENCPP_ROS_H_

#include <opensource/ros/serialization.h>
#include <opensource/ros/message_traits.h>
#include <opensource/ros/message_operations.h>

#include <messaging/ros/ROSMessageFactory.h>
#include <messaging/Message.h>

namespace rframe { class DataTypeInfo; };

#include "sensor_msgs_gencpp_Library.h"

#include "geometry_msgs/geometry_msgs_gencpp_ROS.h"
#include "std_msgs/std_msgs_gencpp_ROS.h"
#include "std_srvs/std_srvs_gencpp_ROS.h"

namespace sensor_msgs { 

    /** definition of message factory for sensor_msgs_gencpp */
    class sensor_msgs_gencppROSMessageFactory : public ROSMessageFactory
    {
    public:
        /** constructor */
        sensor_msgs_gencppROSMessageFactory();
        /** destructor */
        virtual ~sensor_msgs_gencppROSMessageFactory();

        /** see  rframe::MessageFactoryInterface */
        virtual void dataTypes(std::vector<DataTypeInfo> & ids);
        /** see  rframe::MessageFactoryInterface */
        virtual int dataType(ros::SerializedMessage & msg);
        /** see  rframe::MessageFactoryInterface */
        virtual int allocate(rframe::ID_TYPE id, std::shared_ptr<ros::SerializedMessage> & msg);
        /** see  rframe::MessageFactoryInterface */
        virtual int deallocateTransport(ros::SerializedMessage * msg);
        /** see  rframe::MessageFactoryInterface */
        virtual int allocate(rframe::ID_TYPE id, std::shared_ptr<MessageBase> & msg);
        /** see  rframe::MessageFactoryInterface */
        virtual int deallocateMessage(MessageBase * msg);
        /** see  rframe::MessageFactoryInterface */
        virtual int toTransport( MessageBase & src, ros::SerializedMessage & dst);
        /** see  rframe::MessageFactoryInterface */
        virtual int fromTransport( ros::SerializedMessage & src, MessageBase & dst);

		/** see rframe::ROSMessageFactory */
        virtual int typeName(std::string & str, rframe::ID_TYPE id);
		/** see rframe::ROSMessageFactory */
        virtual int desc(std::string & str, rframe::ID_TYPE id);
		/** see rframe::ROSMessageFactory */
        virtual int md5String(std::string & str, rframe::ID_TYPE id);
        /** see rframe::ROSMessageFactory */
        virtual int md5(unsigned long long & highOrder, unsigned long long & lowOrder, rframe::ID_TYPE id);
        /** see rframe::ROSMessageFactory */
		int updateHeader(rframe::MessageBase &msg, unsigned int seqNo);
    };

    /** factory allocation function for use when not dynamically loading the factory library  */
    ROSMessageFactory * allocate_sensor_msgs_gencpp();

}; // end namespace sensor_msgs

// declare ros serialization templates
namespace ros
{
  namespace serialization
  {  

      template <> struct Serializer<sensor_msgs::BatteryState>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::BatteryState & t)
          { 
              stream.next(t.header); 
              stream.next(t.voltage); 
              stream.next(t.current); 
              stream.next(t.charge); 
              stream.next(t.capacity); 
              stream.next(t.design_capacity); 
              stream.next(t.percentage); 
              stream.next(t.power_supply_status); 
              stream.next(t.power_supply_health); 
              stream.next(t.power_supply_technology); 
              stream.next(t.present); 
              stream.next(t.cell_voltage); 
              stream.next(t.location); 
              stream.next(t.serial_number); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::BatteryState & t)
          { 
              stream.next(t.header); 
              stream.next(t.voltage); 
              stream.next(t.current); 
              stream.next(t.charge); 
              stream.next(t.capacity); 
              stream.next(t.design_capacity); 
              stream.next(t.percentage); 
              stream.next(t.power_supply_status); 
              stream.next(t.power_supply_health); 
              stream.next(t.power_supply_technology); 
              stream.next(t.present); 
              stream.next(t.cell_voltage); 
              stream.next(t.location); 
              stream.next(t.serial_number); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::BatteryState & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.voltage); 
              size += serializationLength(t.current); 
              size += serializationLength(t.charge); 
              size += serializationLength(t.capacity); 
              size += serializationLength(t.design_capacity); 
              size += serializationLength(t.percentage); 
              size += serializationLength(t.power_supply_status); 
              size += serializationLength(t.power_supply_health); 
              size += serializationLength(t.power_supply_technology); 
              size += serializationLength(t.present); 
              size += serializationLength(t.cell_voltage); 
              size += serializationLength(t.location); 
              size += serializationLength(t.serial_number); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::BatteryState>

      template <> struct Serializer<sensor_msgs::CameraInfo>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::CameraInfo & t)
          { 
              stream.next(t.header); 
              stream.next(t.height); 
              stream.next(t.width); 
              stream.next(t.distortion_model); 
              stream.next(t.D); 
              stream.next(t.K); 
              stream.next(t.R); 
              stream.next(t.P); 
              stream.next(t.binning_x); 
              stream.next(t.binning_y); 
              stream.next(t.roi); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::CameraInfo & t)
          { 
              stream.next(t.header); 
              stream.next(t.height); 
              stream.next(t.width); 
              stream.next(t.distortion_model); 
              stream.next(t.D); 
              stream.next(t.K); 
              stream.next(t.R); 
              stream.next(t.P); 
              stream.next(t.binning_x); 
              stream.next(t.binning_y); 
              stream.next(t.roi); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::CameraInfo & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.height); 
              size += serializationLength(t.width); 
              size += serializationLength(t.distortion_model); 
              size += serializationLength(t.D); 
              size += serializationLength(t.K); 
              size += serializationLength(t.R); 
              size += serializationLength(t.P); 
              size += serializationLength(t.binning_x); 
              size += serializationLength(t.binning_y); 
              size += serializationLength(t.roi); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::CameraInfo>

      template <> struct Serializer<sensor_msgs::ChannelFloat32>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::ChannelFloat32 & t)
          { 
              stream.next(t.name); 
              stream.next(t.values); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::ChannelFloat32 & t)
          { 
              stream.next(t.name); 
              stream.next(t.values); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::ChannelFloat32 & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.name); 
              size += serializationLength(t.values); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::ChannelFloat32>

      template <> struct Serializer<sensor_msgs::CompressedImage>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::CompressedImage & t)
          { 
              stream.next(t.header); 
              stream.next(t.format); 
              stream.next(t.data); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::CompressedImage & t)
          { 
              stream.next(t.header); 
              stream.next(t.format); 
              stream.next(t.data); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::CompressedImage & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.format); 
              size += serializationLength(t.data); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::CompressedImage>

      template <> struct Serializer<sensor_msgs::FluidPressure>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::FluidPressure & t)
          { 
              stream.next(t.header); 
              stream.next(t.fluid_pressure); 
              stream.next(t.variance); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::FluidPressure & t)
          { 
              stream.next(t.header); 
              stream.next(t.fluid_pressure); 
              stream.next(t.variance); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::FluidPressure & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.fluid_pressure); 
              size += serializationLength(t.variance); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::FluidPressure>

      template <> struct Serializer<sensor_msgs::Illuminance>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::Illuminance & t)
          { 
              stream.next(t.header); 
              stream.next(t.illuminance); 
              stream.next(t.variance); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::Illuminance & t)
          { 
              stream.next(t.header); 
              stream.next(t.illuminance); 
              stream.next(t.variance); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::Illuminance & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.illuminance); 
              size += serializationLength(t.variance); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::Illuminance>

      template <> struct Serializer<sensor_msgs::Image>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::Image & t)
          { 
              stream.next(t.header); 
              stream.next(t.height); 
              stream.next(t.width); 
              stream.next(t.encoding); 
              stream.next(t.is_bigendian); 
              stream.next(t.step); 
              stream.next(t.data); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::Image & t)
          { 
              stream.next(t.header); 
              stream.next(t.height); 
              stream.next(t.width); 
              stream.next(t.encoding); 
              stream.next(t.is_bigendian); 
              stream.next(t.step); 
              stream.next(t.data); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::Image & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.height); 
              size += serializationLength(t.width); 
              size += serializationLength(t.encoding); 
              size += serializationLength(t.is_bigendian); 
              size += serializationLength(t.step); 
              size += serializationLength(t.data); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::Image>

      template <> struct Serializer<sensor_msgs::Imu>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::Imu & t)
          { 
              stream.next(t.header); 
              stream.next(t.orientation); 
              stream.next(t.orientation_covariance); 
              stream.next(t.angular_velocity); 
              stream.next(t.angular_velocity_covariance); 
              stream.next(t.linear_acceleration); 
              stream.next(t.linear_acceleration_covariance); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::Imu & t)
          { 
              stream.next(t.header); 
              stream.next(t.orientation); 
              stream.next(t.orientation_covariance); 
              stream.next(t.angular_velocity); 
              stream.next(t.angular_velocity_covariance); 
              stream.next(t.linear_acceleration); 
              stream.next(t.linear_acceleration_covariance); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::Imu & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.orientation); 
              size += serializationLength(t.orientation_covariance); 
              size += serializationLength(t.angular_velocity); 
              size += serializationLength(t.angular_velocity_covariance); 
              size += serializationLength(t.linear_acceleration); 
              size += serializationLength(t.linear_acceleration_covariance); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::Imu>

      template <> struct Serializer<sensor_msgs::JointState>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::JointState & t)
          { 
              stream.next(t.header); 
              stream.next(t.name); 
              stream.next(t.position); 
              stream.next(t.velocity); 
              stream.next(t.effort); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::JointState & t)
          { 
              stream.next(t.header); 
              stream.next(t.name); 
              stream.next(t.position); 
              stream.next(t.velocity); 
              stream.next(t.effort); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::JointState & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.name); 
              size += serializationLength(t.position); 
              size += serializationLength(t.velocity); 
              size += serializationLength(t.effort); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::JointState>

      template <> struct Serializer<sensor_msgs::Joy>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::Joy & t)
          { 
              stream.next(t.header); 
              stream.next(t.axes); 
              stream.next(t.buttons); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::Joy & t)
          { 
              stream.next(t.header); 
              stream.next(t.axes); 
              stream.next(t.buttons); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::Joy & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.axes); 
              size += serializationLength(t.buttons); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::Joy>

      template <> struct Serializer<sensor_msgs::JoyFeedback>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::JoyFeedback & t)
          { 
              stream.next(t.type); 
              stream.next(t.id); 
              stream.next(t.intensity); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::JoyFeedback & t)
          { 
              stream.next(t.type); 
              stream.next(t.id); 
              stream.next(t.intensity); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::JoyFeedback & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.type); 
              size += serializationLength(t.id); 
              size += serializationLength(t.intensity); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::JoyFeedback>

      template <> struct Serializer<sensor_msgs::JoyFeedbackArray>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::JoyFeedbackArray & t)
          { 
              stream.next(t.array); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::JoyFeedbackArray & t)
          { 
              stream.next(t.array); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::JoyFeedbackArray & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.array); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::JoyFeedbackArray>

      template <> struct Serializer<sensor_msgs::LaserEcho>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::LaserEcho & t)
          { 
              stream.next(t.echoes); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::LaserEcho & t)
          { 
              stream.next(t.echoes); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::LaserEcho & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.echoes); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::LaserEcho>

      template <> struct Serializer<sensor_msgs::LaserScan>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::LaserScan & t)
          { 
              stream.next(t.header); 
              stream.next(t.angle_min); 
              stream.next(t.angle_max); 
              stream.next(t.angle_increment); 
              stream.next(t.time_increment); 
              stream.next(t.scan_time); 
              stream.next(t.range_min); 
              stream.next(t.range_max); 
              stream.next(t.ranges); 
              stream.next(t.intensities); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::LaserScan & t)
          { 
              stream.next(t.header); 
              stream.next(t.angle_min); 
              stream.next(t.angle_max); 
              stream.next(t.angle_increment); 
              stream.next(t.time_increment); 
              stream.next(t.scan_time); 
              stream.next(t.range_min); 
              stream.next(t.range_max); 
              stream.next(t.ranges); 
              stream.next(t.intensities); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::LaserScan & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.angle_min); 
              size += serializationLength(t.angle_max); 
              size += serializationLength(t.angle_increment); 
              size += serializationLength(t.time_increment); 
              size += serializationLength(t.scan_time); 
              size += serializationLength(t.range_min); 
              size += serializationLength(t.range_max); 
              size += serializationLength(t.ranges); 
              size += serializationLength(t.intensities); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::LaserScan>

      template <> struct Serializer<sensor_msgs::MagneticField>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::MagneticField & t)
          { 
              stream.next(t.header); 
              stream.next(t.magnetic_field); 
              stream.next(t.magnetic_field_covariance); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::MagneticField & t)
          { 
              stream.next(t.header); 
              stream.next(t.magnetic_field); 
              stream.next(t.magnetic_field_covariance); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::MagneticField & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.magnetic_field); 
              size += serializationLength(t.magnetic_field_covariance); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::MagneticField>

      template <> struct Serializer<sensor_msgs::MultiDOFJointState>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::MultiDOFJointState & t)
          { 
              stream.next(t.header); 
              stream.next(t.joint_names); 
              stream.next(t.transforms); 
              stream.next(t.twist); 
              stream.next(t.wrench); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::MultiDOFJointState & t)
          { 
              stream.next(t.header); 
              stream.next(t.joint_names); 
              stream.next(t.transforms); 
              stream.next(t.twist); 
              stream.next(t.wrench); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::MultiDOFJointState & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.joint_names); 
              size += serializationLength(t.transforms); 
              size += serializationLength(t.twist); 
              size += serializationLength(t.wrench); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::MultiDOFJointState>

      template <> struct Serializer<sensor_msgs::MultiEchoLaserScan>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::MultiEchoLaserScan & t)
          { 
              stream.next(t.header); 
              stream.next(t.angle_min); 
              stream.next(t.angle_max); 
              stream.next(t.angle_increment); 
              stream.next(t.time_increment); 
              stream.next(t.scan_time); 
              stream.next(t.range_min); 
              stream.next(t.range_max); 
              stream.next(t.ranges); 
              stream.next(t.intensities); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::MultiEchoLaserScan & t)
          { 
              stream.next(t.header); 
              stream.next(t.angle_min); 
              stream.next(t.angle_max); 
              stream.next(t.angle_increment); 
              stream.next(t.time_increment); 
              stream.next(t.scan_time); 
              stream.next(t.range_min); 
              stream.next(t.range_max); 
              stream.next(t.ranges); 
              stream.next(t.intensities); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::MultiEchoLaserScan & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.angle_min); 
              size += serializationLength(t.angle_max); 
              size += serializationLength(t.angle_increment); 
              size += serializationLength(t.time_increment); 
              size += serializationLength(t.scan_time); 
              size += serializationLength(t.range_min); 
              size += serializationLength(t.range_max); 
              size += serializationLength(t.ranges); 
              size += serializationLength(t.intensities); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::MultiEchoLaserScan>

      template <> struct Serializer<sensor_msgs::NavSatFix>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::NavSatFix & t)
          { 
              stream.next(t.header); 
              stream.next(t.status); 
              stream.next(t.latitude); 
              stream.next(t.longitude); 
              stream.next(t.altitude); 
              stream.next(t.position_covariance); 
              stream.next(t.position_covariance_type); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::NavSatFix & t)
          { 
              stream.next(t.header); 
              stream.next(t.status); 
              stream.next(t.latitude); 
              stream.next(t.longitude); 
              stream.next(t.altitude); 
              stream.next(t.position_covariance); 
              stream.next(t.position_covariance_type); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::NavSatFix & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.status); 
              size += serializationLength(t.latitude); 
              size += serializationLength(t.longitude); 
              size += serializationLength(t.altitude); 
              size += serializationLength(t.position_covariance); 
              size += serializationLength(t.position_covariance_type); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::NavSatFix>

      template <> struct Serializer<sensor_msgs::NavSatStatus>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::NavSatStatus & t)
          { 
              stream.next(t.status); 
              stream.next(t.service); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::NavSatStatus & t)
          { 
              stream.next(t.status); 
              stream.next(t.service); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::NavSatStatus & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.status); 
              size += serializationLength(t.service); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::NavSatStatus>

      template <> struct Serializer<sensor_msgs::PointCloud>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::PointCloud & t)
          { 
              stream.next(t.header); 
              stream.next(t.points); 
              stream.next(t.channels); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::PointCloud & t)
          { 
              stream.next(t.header); 
              stream.next(t.points); 
              stream.next(t.channels); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::PointCloud & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.points); 
              size += serializationLength(t.channels); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::PointCloud>

      template <> struct Serializer<sensor_msgs::PointCloud2>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::PointCloud2 & t)
          { 
              stream.next(t.header); 
              stream.next(t.height); 
              stream.next(t.width); 
              stream.next(t.fields); 
              stream.next(t.is_bigendian); 
              stream.next(t.point_step); 
              stream.next(t.row_step); 
              stream.next(t.data); 
              stream.next(t.is_dense); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::PointCloud2 & t)
          { 
              stream.next(t.header); 
              stream.next(t.height); 
              stream.next(t.width); 
              stream.next(t.fields); 
              stream.next(t.is_bigendian); 
              stream.next(t.point_step); 
              stream.next(t.row_step); 
              stream.next(t.data); 
              stream.next(t.is_dense); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::PointCloud2 & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.height); 
              size += serializationLength(t.width); 
              size += serializationLength(t.fields); 
              size += serializationLength(t.is_bigendian); 
              size += serializationLength(t.point_step); 
              size += serializationLength(t.row_step); 
              size += serializationLength(t.data); 
              size += serializationLength(t.is_dense); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::PointCloud2>

      template <> struct Serializer<sensor_msgs::PointField>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::PointField & t)
          { 
              stream.next(t.name); 
              stream.next(t.offset); 
              stream.next(t.datatype); 
              stream.next(t.count); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::PointField & t)
          { 
              stream.next(t.name); 
              stream.next(t.offset); 
              stream.next(t.datatype); 
              stream.next(t.count); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::PointField & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.name); 
              size += serializationLength(t.offset); 
              size += serializationLength(t.datatype); 
              size += serializationLength(t.count); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::PointField>

      template <> struct Serializer<sensor_msgs::Range>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::Range & t)
          { 
              stream.next(t.header); 
              stream.next(t.radiation_type); 
              stream.next(t.field_of_view); 
              stream.next(t.min_range); 
              stream.next(t.max_range); 
              stream.next(t.range); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::Range & t)
          { 
              stream.next(t.header); 
              stream.next(t.radiation_type); 
              stream.next(t.field_of_view); 
              stream.next(t.min_range); 
              stream.next(t.max_range); 
              stream.next(t.range); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::Range & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.radiation_type); 
              size += serializationLength(t.field_of_view); 
              size += serializationLength(t.min_range); 
              size += serializationLength(t.max_range); 
              size += serializationLength(t.range); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::Range>

      template <> struct Serializer<sensor_msgs::RegionOfInterest>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::RegionOfInterest & t)
          { 
              stream.next(t.x_offset); 
              stream.next(t.y_offset); 
              stream.next(t.height); 
              stream.next(t.width); 
              stream.next(t.do_rectify); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::RegionOfInterest & t)
          { 
              stream.next(t.x_offset); 
              stream.next(t.y_offset); 
              stream.next(t.height); 
              stream.next(t.width); 
              stream.next(t.do_rectify); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::RegionOfInterest & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.x_offset); 
              size += serializationLength(t.y_offset); 
              size += serializationLength(t.height); 
              size += serializationLength(t.width); 
              size += serializationLength(t.do_rectify); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::RegionOfInterest>

      template <> struct Serializer<sensor_msgs::RelativeHumidity>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::RelativeHumidity & t)
          { 
              stream.next(t.header); 
              stream.next(t.relative_humidity); 
              stream.next(t.variance); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::RelativeHumidity & t)
          { 
              stream.next(t.header); 
              stream.next(t.relative_humidity); 
              stream.next(t.variance); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::RelativeHumidity & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.relative_humidity); 
              size += serializationLength(t.variance); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::RelativeHumidity>

      template <> struct Serializer<sensor_msgs::Temperature>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::Temperature & t)
          { 
              stream.next(t.header); 
              stream.next(t.temperature); 
              stream.next(t.variance); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::Temperature & t)
          { 
              stream.next(t.header); 
              stream.next(t.temperature); 
              stream.next(t.variance); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::Temperature & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.temperature); 
              size += serializationLength(t.variance); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::Temperature>

      template <> struct Serializer<sensor_msgs::TimeReference>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::TimeReference & t)
          { 
              stream.next(t.header); 
              stream.next(t.time_ref); 
              stream.next(t.source); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::TimeReference & t)
          { 
              stream.next(t.header); 
              stream.next(t.time_ref); 
              stream.next(t.source); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::TimeReference & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.header); 
              size += serializationLength(t.time_ref); 
              size += serializationLength(t.source); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::TimeReference>

      template <> struct Serializer<sensor_msgs::SetCameraInfoRequest>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::SetCameraInfoRequest & t)
          { 
              stream.next(t.camera_info); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::SetCameraInfoRequest & t)
          { 
              stream.next(t.camera_info); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::SetCameraInfoRequest & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.camera_info); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::SetCameraInfoRequest>

      template <> struct Serializer<sensor_msgs::SetCameraInfoResponse>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::SetCameraInfoResponse & t)
          { 
              stream.next(t.success); 
              stream.next(t.status_message); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::SetCameraInfoResponse & t)
          { 
              stream.next(t.success); 
              stream.next(t.status_message); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::SetCameraInfoResponse & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.success); 
              size += serializationLength(t.status_message); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::SetCameraInfoResponse>

      template <> struct Serializer<sensor_msgs::SetCameraInfo>
      {
          template <typename Stream> inline static void write(Stream & stream, const sensor_msgs::SetCameraInfo & t)
          { 
              stream.next(t.request); 
              stream.next(t.response); 
          };

          template <typename Stream> inline static void read(Stream & stream, sensor_msgs::SetCameraInfo & t)
          { 
              stream.next(t.request); 
              stream.next(t.response); 
          };

          inline static uint32_t serializedLength(const sensor_msgs::SetCameraInfo & t)
          { 
              uint32_t size = 0;

              size += serializationLength(t.request); 
              size += serializationLength(t.response); 
              return size;
          };
      }; // end struct Serializer<sensor_msgs::SetCameraInfo>

  }; // namespace serialization

  namespace message_traits
  {

      template <> struct MD5Sum<sensor_msgs::BatteryState>
      {

          static const char * value() 
          { 
              return "476f837fa6771f6e16e3bf4ef96f8770"; 
          };

          static const uint64_t static_value1 = 0x476f837fa6771f6eULL;
          static const uint64_t static_value2 = 0x16e3bf4ef96f8770ULL;
      }; // end struct MD5Sum<sensor_msgs::BatteryState>

      template <> struct DataType<sensor_msgs::BatteryState>
      {
          static const char * value() { return "sensor_msgs/BatteryState";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::BatteryState>
      {
          static const char * value()
          { 
              return "\n# Constants are chosen to match the enums in the linux kernel\n# defined in include/linux/power_supply.h as of version 3.7\n# The one difference is for style reasons the constants are\n# all uppercase not mixed case.\n\n# Power supply status constants\nuint8 POWER_SUPPLY_STATUS_UNKNOWN = 0\nuint8 POWER_SUPPLY_STATUS_CHARGING = 1\nuint8 POWER_SUPPLY_STATUS_DISCHARGING = 2\nuint8 POWER_SUPPLY_STATUS_NOT_CHARGING = 3\nuint8 POWER_SUPPLY_STATUS_FULL = 4\n\n# Power supply health constants\nuint8 POWER_SUPPLY_HEALTH_UNKNOWN = 0\nuint8 POWER_SUPPLY_HEALTH_GOOD = 1\nuint8 POWER_SUPPLY_HEALTH_OVERHEAT = 2\nuint8 POWER_SUPPLY_HEALTH_DEAD = 3\nuint8 POWER_SUPPLY_HEALTH_OVERVOLTAGE = 4\nuint8 POWER_SUPPLY_HEALTH_UNSPEC_FAILURE = 5\nuint8 POWER_SUPPLY_HEALTH_COLD = 6\nuint8 POWER_SUPPLY_HEALTH_WATCHDOG_TIMER_EXPIRE = 7\nuint8 POWER_SUPPLY_HEALTH_SAFETY_TIMER_EXPIRE = 8\n\n# Power supply technology (chemistry) constants\nuint8 POWER_SUPPLY_TECHNOLOGY_UNKNOWN = 0\nuint8 POWER_SUPPLY_TECHNOLOGY_NIMH = 1\nuint8 POWER_SUPPLY_TECHNOLOGY_LION = 2\nuint8 POWER_SUPPLY_TECHNOLOGY_LIPO = 3\nuint8 POWER_SUPPLY_TECHNOLOGY_LIFE = 4\nuint8 POWER_SUPPLY_TECHNOLOGY_NICD = 5\nuint8 POWER_SUPPLY_TECHNOLOGY_LIMN = 6\n\nHeader  header\nfloat32 voltage          # Voltage in Volts (Mandatory)\nfloat32 current          # Negative when discharging (A)  (If unmeasured NaN)\nfloat32 charge           # Current charge in Ah  (If unmeasured NaN)\nfloat32 capacity         # Capacity in Ah (last full capacity)  (If unmeasured NaN)\nfloat32 design_capacity  # Capacity in Ah (design capacity)  (If unmeasured NaN)\nfloat32 percentage       # Charge percentage on 0 to 1 range  (If unmeasured NaN)\nuint8   power_supply_status     # The charging status as reported. Values defined above\nuint8   power_supply_health     # The battery health metric. Values defined above\nuint8   power_supply_technology # The battery chemistry. Values defined above\nbool    present          # True if the battery is present\n\nfloat32[] cell_voltage   # An array of individual cell voltages for each cell in the pack\n                         # If individual voltages unknown but number of cells known set each to NaN\nstring location          # The location into which the battery is inserted. (slot number or plug)\nstring serial_number     # The best approximation of the battery serial number\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::CameraInfo>
      {

          static const char * value() 
          { 
              return "c9a58c1b0b154e0e6da7578cb991d214"; 
          };

          static const uint64_t static_value1 = 0xc9a58c1b0b154e0eULL;
          static const uint64_t static_value2 = 0x6da7578cb991d214ULL;
      }; // end struct MD5Sum<sensor_msgs::CameraInfo>

      template <> struct DataType<sensor_msgs::CameraInfo>
      {
          static const char * value() { return "sensor_msgs/CameraInfo";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::CameraInfo>
      {
          static const char * value()
          { 
              return "# This message defines meta information for a camera. It should be in a\n# camera namespace on topic \"camera_info\" and accompanied by up to five\n# image topics named:\n#\n#   image_raw - raw data from the camera driver, possibly Bayer encoded\n#   image            - monochrome, distorted\n#   image_color      - color, distorted\n#   image_rect       - monochrome, rectified\n#   image_rect_color - color, rectified\n#\n# The image_pipeline contains packages (image_proc, stereo_image_proc)\n# for producing the four processed image topics from image_raw and\n# camera_info. The meaning of the camera parameters are described in\n# detail at http://www.ros.org/wiki/image_pipeline/CameraInfo.\n#\n# The image_geometry package provides a user-friendly interface to\n# common operations using this meta information. If you want to, e.g.,\n# project a 3d point into image coordinates, we strongly recommend\n# using image_geometry.\n#\n# If the camera is uncalibrated, the matrices D, K, R, P should be left\n# zeroed out. In particular, clients may assume that K[0] == 0.0\n# indicates an uncalibrated camera.\n\n#######################################################################\n#                     Image acquisition info                          #\n#######################################################################\n\n# Time of image acquisition, camera coordinate frame ID\nHeader header    # Header timestamp should be acquisition time of image\n                 # Header frame_id should be optical frame of camera\n                 # origin of frame should be optical center of camera\n                 # +x should point to the right in the image\n                 # +y should point down in the image\n                 # +z should point into the plane of the image\n\n\n#######################################################################\n#                      Calibration Parameters                         #\n#######################################################################\n# These are fixed during camera calibration. Their values will be the #\n# same in all messages until the camera is recalibrated. Note that    #\n# self-calibrating systems may \"recalibrate\" frequently.              #\n#                                                                     #\n# The internal parameters can be used to warp a raw (distorted) image #\n# to:                                                                 #\n#   1. An undistorted image (requires D and K)                        #\n#   2. A rectified image (requires D, K, R)                           #\n# The projection matrix P projects 3D points into the rectified image.#\n#######################################################################\n\n# The image dimensions with which the camera was calibrated. Normally\n# this will be the full camera resolution in pixels.\nuint32 height\nuint32 width\n\n# The distortion model used. Supported models are listed in\n# sensor_msgs/distortion_models.h. For most cameras, \"plumb_bob\" - a\n# simple model of radial and tangential distortion - is sufficent.\nstring distortion_model\n\n# The distortion parameters, size depending on the distortion model.\n# For \"plumb_bob\", the 5 parameters are: (k1, k2, t1, t2, k3).\nfloat64[] D\n\n# Intrinsic camera matrix for the raw (distorted) images.\n#     [fx  0 cx]\n# K = [ 0 fy cy]\n#     [ 0  0  1]\n# Projects 3D points in the camera coordinate frame to 2D pixel\n# coordinates using the focal lengths (fx, fy) and principal point\n# (cx, cy).\nfloat64[9]  K # 3x3 row-major matrix\n\n# Rectification matrix (stereo cameras only)\n# A rotation matrix aligning the camera coordinate system to the ideal\n# stereo image plane so that epipolar lines in both stereo images are\n# parallel.\nfloat64[9]  R # 3x3 row-major matrix\n\n# Projection/camera matrix\n#     [fx'  0  cx' Tx]\n# P = [ 0  fy' cy' Ty]\n#     [ 0   0   1   0]\n# By convention, this matrix specifies the intrinsic (camera) matrix\n#  of the processed (rectified) image. That is, the left 3x3 portion\n#  is the normal camera intrinsic matrix for the rectified image.\n# It projects 3D points in the camera coordinate frame to 2D pixel\n#  coordinates using the focal lengths (fx', fy') and principal point\n#  (cx', cy') - these may differ from the values in K.\n# For monocular cameras, Tx = Ty = 0. Normally, monocular cameras will\n#  also have R = the identity and P[1:3,1:3] = K.\n# For a stereo pair, the fourth column [Tx Ty 0]' is related to the\n#  position of the optical center of the second camera in the first\n#  camera's frame. We assume Tz = 0 so both cameras are in the same\n#  stereo image plane. The first camera always has Tx = Ty = 0. For\n#  the right (second) camera of a horizontal stereo pair, Ty = 0 and\n#  Tx = -fx' * B, where B is the baseline between the cameras.\n# Given a 3D point [X Y Z]', the projection (x, y) of the point onto\n#  the rectified image is given by:\n#  [u v w]' = P * [X Y Z 1]'\n#         x = u / w\n#         y = v / w\n#  This holds for both images of a stereo pair.\nfloat64[12] P # 3x4 row-major matrix\n\n\n#######################################################################\n#                      Operational Parameters                         #\n#######################################################################\n# These define the image region actually captured by the camera       #\n# driver. Although they affect the geometry of the output image, they #\n# may be changed freely without recalibrating the camera.             #\n#######################################################################\n\n# Binning refers here to any camera setting which combines rectangular\n#  neighborhoods of pixels into larger \"super-pixels.\" It reduces the\n#  resolution of the output image to\n#  (width / binning_x) x (height / binning_y).\n# The default values binning_x = binning_y = 0 is considered the same\n#  as binning_x = binning_y = 1 (no subsampling).\nuint32 binning_x\nuint32 binning_y\n\n# Region of interest (subwindow of full camera resolution), given in\n#  full resolution (unbinned) image coordinates. A particular ROI\n#  always denotes the same window of pixels on the camera sensor,\n#  regardless of binning settings.\n# The default setting of roi (all values 0) is considered the same as\n#  full resolution (roi.width = width, roi.height = height).\nRegionOfInterest roi\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n\n================================================================================\nMSG: sensor_msgs/RegionOfInterest\n# This message is used to specify a region of interest within an image.\n#\n# When used to specify the ROI setting of the camera when the image was\n# taken, the height and width fields should either match the height and\n# width fields for the associated image; or height = width = 0\n# indicates that the full resolution image was captured.\n\nuint32 x_offset  # Leftmost pixel of the ROI\n                 # (0 if the ROI includes the left edge of the image)\nuint32 y_offset  # Topmost pixel of the ROI\n                 # (0 if the ROI includes the top edge of the image)\nuint32 height    # Height of ROI\nuint32 width     # Width of ROI\n\n# True if a distinct rectified ROI should be calculated from the \"raw\"\n# ROI in this message. Typically this should be False if the full image\n# is captured (ROI not used), and True if a subwindow is captured (ROI\n# used).\nbool do_rectify\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::ChannelFloat32>
      {

          static const char * value() 
          { 
              return "3d40139cdd33dfedcb71ffeeeb42ae7f"; 
          };

          static const uint64_t static_value1 = 0x3d40139cdd33dfedULL;
          static const uint64_t static_value2 = 0xcb71ffeeeb42ae7fULL;
      }; // end struct MD5Sum<sensor_msgs::ChannelFloat32>

      template <> struct DataType<sensor_msgs::ChannelFloat32>
      {
          static const char * value() { return "sensor_msgs/ChannelFloat32";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::ChannelFloat32>
      {
          static const char * value()
          { 
              return "# This message is used by the PointCloud message to hold optional data\n# associated with each point in the cloud. The length of the values\n# array should be the same as the length of the points array in the\n# PointCloud, and each value should be associated with the corresponding\n# point.\n\n# Channel names in existing practice include:\n#   \"u\", \"v\" - row and column (respectively) in the left stereo image.\n#              This is opposite to usual conventions but remains for\n#              historical reasons. The newer PointCloud2 message has no\n#              such problem.\n#   \"rgb\" - For point clouds produced by color stereo cameras. uint8\n#           (R,G,B) values packed into the least significant 24 bits,\n#           in order.\n#   \"intensity\" - laser or pixel intensity.\n#   \"distance\"\n\n# The channel name should give semantics of the channel (e.g.\n# \"intensity\" instead of \"value\").\nstring name\n\n# The values array should be 1-1 with the elements of the associated\n# PointCloud.\nfloat32[] values\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::CompressedImage>
      {

          static const char * value() 
          { 
              return "8f7a12909da2c9d3332d540a0977563f"; 
          };

          static const uint64_t static_value1 = 0x8f7a12909da2c9d3ULL;
          static const uint64_t static_value2 = 0x332d540a0977563fULL;
      }; // end struct MD5Sum<sensor_msgs::CompressedImage>

      template <> struct DataType<sensor_msgs::CompressedImage>
      {
          static const char * value() { return "sensor_msgs/CompressedImage";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::CompressedImage>
      {
          static const char * value()
          { 
              return "# This message contains a compressed image\n\nHeader header        # Header timestamp should be acquisition time of image\n                     # Header frame_id should be optical frame of camera\n                     # origin of frame should be optical center of cameara\n                     # +x should point to the right in the image\n                     # +y should point down in the image\n                     # +z should point into to plane of the image\n\nstring format        # Specifies the format of the data\n                     #   Acceptable values:\n                     #     jpeg, png\nuint8[] data         # Compressed image buffer\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::FluidPressure>
      {

          static const char * value() 
          { 
              return "804dc5cea1c5306d6a2eb80b9833befe"; 
          };

          static const uint64_t static_value1 = 0x804dc5cea1c5306dULL;
          static const uint64_t static_value2 = 0x6a2eb80b9833befeULL;
      }; // end struct MD5Sum<sensor_msgs::FluidPressure>

      template <> struct DataType<sensor_msgs::FluidPressure>
      {
          static const char * value() { return "sensor_msgs/FluidPressure";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::FluidPressure>
      {
          static const char * value()
          { 
              return "# Single pressure reading.  This message is appropriate for measuring the\n # pressure inside of a fluid (air, water, etc).  This also includes\n # atmospheric or barometric pressure.\n\n # This message is not appropriate for force/pressure contact sensors.\n\n Header header           # timestamp of the measurement\n                         # frame_id is the location of the pressure sensor\n\n float64 fluid_pressure  # Absolute pressure reading in Pascals.\n\n float64 variance        # 0 is interpreted as variance unknown\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::Illuminance>
      {

          static const char * value() 
          { 
              return "8cf5febb0952fca9d650c3d11a81a188"; 
          };

          static const uint64_t static_value1 = 0x8cf5febb0952fca9ULL;
          static const uint64_t static_value2 = 0xd650c3d11a81a188ULL;
      }; // end struct MD5Sum<sensor_msgs::Illuminance>

      template <> struct DataType<sensor_msgs::Illuminance>
      {
          static const char * value() { return "sensor_msgs/Illuminance";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::Illuminance>
      {
          static const char * value()
          { 
              return "# Single photometric illuminance measurement.  Light should be assumed to be\n # measured along the sensor's x-axis (the area of detection is the y-z plane).\n # The illuminance should have a 0 or positive value and be received with\n # the sensor's +X axis pointing toward the light source.\n\n # Photometric illuminance is the measure of the human eye's sensitivity of the\n # intensity of light encountering or passing through a surface.\n\n # All other Photometric and Radiometric measurements should\n # not use this message.\n # This message cannot represent:\n # Luminous intensity (candela/light source output)\n # Luminance (nits/light output per area)\n # Irradiance (watt/area), etc.\n\n Header header           # timestamp is the time the illuminance was measured\n                         # frame_id is the location and direction of the reading\n\n float64 illuminance     # Measurement of the Photometric Illuminance in Lux.\n\n float64 variance        # 0 is interpreted as variance unknown\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::Image>
      {

          static const char * value() 
          { 
              return "060021388200f6f0f447d0fcd9c64743"; 
          };

          static const uint64_t static_value1 = 0x060021388200f6f0ULL;
          static const uint64_t static_value2 = 0xf447d0fcd9c64743ULL;
      }; // end struct MD5Sum<sensor_msgs::Image>

      template <> struct DataType<sensor_msgs::Image>
      {
          static const char * value() { return "sensor_msgs/Image";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::Image>
      {
          static const char * value()
          { 
              return "# This message contains an uncompressed image\n# (0, 0) is at top-left corner of image\n#\n\nHeader header        # Header timestamp should be acquisition time of image\n                     # Header frame_id should be optical frame of camera\n                     # origin of frame should be optical center of cameara\n                     # +x should point to the right in the image\n                     # +y should point down in the image\n                     # +z should point into to plane of the image\n                     # If the frame_id here and the frame_id of the CameraInfo\n                     # message associated with the image conflict\n                     # the behavior is undefined\n\nuint32 height         # image height, that is, number of rows\nuint32 width          # image width, that is, number of columns\n\n# The legal values for encoding are in file src/image_encodings.cpp\n# If you want to standardize a new string format, join\n# ros-users@lists.sourceforge.net and send an email proposing a new encoding.\n\nstring encoding       # Encoding of pixels -- channel meaning, ordering, size\n                      # taken from the list of strings in include/sensor_msgs/image_encodings.h\n\nuint8 is_bigendian    # is this data bigendian?\nuint32 step           # Full row length in bytes\nuint8[] data          # actual matrix data, size is (step * rows)\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::Imu>
      {

          static const char * value() 
          { 
              return "6a62c6daae103f4ff57a132d6f95cec2"; 
          };

          static const uint64_t static_value1 = 0x6a62c6daae103f4fULL;
          static const uint64_t static_value2 = 0xf57a132d6f95cec2ULL;
      }; // end struct MD5Sum<sensor_msgs::Imu>

      template <> struct DataType<sensor_msgs::Imu>
      {
          static const char * value() { return "sensor_msgs/Imu";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::Imu>
      {
          static const char * value()
          { 
              return "# This is a message to hold data from an IMU (Inertial Measurement Unit)\n#\n# Accelerations should be in m/s^2 (not in g's), and rotational velocity should be in rad/sec\n#\n# If the covariance of the measurement is known, it should be filled in (if all you know is the \n# variance of each measurement, e.g. from the datasheet, just put those along the diagonal)\n# A covariance matrix of all zeros will be interpreted as \"covariance unknown\", and to use the\n# data a covariance will have to be assumed or gotten from some other source\n#\n# If you have no estimate for one of the data elements (e.g. your IMU doesn't produce an orientation \n# estimate), please set element 0 of the associated covariance matrix to -1\n# If you are interpreting this message, please check for a value of -1 in the first element of each \n# covariance matrix, and disregard the associated estimate.\n\nHeader header\n\ngeometry_msgs/Quaternion orientation\nfloat64[9] orientation_covariance # Row major about x, y, z axes\n\ngeometry_msgs/Vector3 angular_velocity\nfloat64[9] angular_velocity_covariance # Row major about x, y, z axes\n\ngeometry_msgs/Vector3 linear_acceleration\nfloat64[9] linear_acceleration_covariance # Row major x, y z \n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n\n================================================================================\nMSG: geometry_msgs/Quaternion\n# This represents an orientation in free space in quaternion form.\n\nfloat64 x\nfloat64 y\nfloat64 z\nfloat64 w\n\n================================================================================\nMSG: geometry_msgs/Vector3\n# This represents a vector in free space. \n# It is only meant to represent a direction. Therefore, it does not\n# make sense to apply a translation to it (e.g., when applying a \n# generic rigid transformation to a Vector3, tf2 will only apply the\n# rotation). If you want your data to be translatable too, use the\n# geometry_msgs/Point message instead.\n\nfloat64 x\nfloat64 y\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::JointState>
      {

          static const char * value() 
          { 
              return "3066dcd76a6cfaef579bd0f34173e9fd"; 
          };

          static const uint64_t static_value1 = 0x3066dcd76a6cfaefULL;
          static const uint64_t static_value2 = 0x579bd0f34173e9fdULL;
      }; // end struct MD5Sum<sensor_msgs::JointState>

      template <> struct DataType<sensor_msgs::JointState>
      {
          static const char * value() { return "sensor_msgs/JointState";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::JointState>
      {
          static const char * value()
          { 
              return "# This is a message that holds data to describe the state of a set of torque controlled joints. \n#\n# The state of each joint (revolute or prismatic) is defined by:\n#  * the position of the joint (rad or m),\n#  * the velocity of the joint (rad/s or m/s) and \n#  * the effort that is applied in the joint (Nm or N).\n#\n# Each joint is uniquely identified by its name\n# The header specifies the time at which the joint states were recorded. All the joint states\n# in one message have to be recorded at the same time.\n#\n# This message consists of a multiple arrays, one for each part of the joint state. \n# The goal is to make each of the fields optional. When e.g. your joints have no\n# effort associated with them, you can leave the effort array empty. \n#\n# All arrays in this message should have the same size, or be empty.\n# This is the only way to uniquely associate the joint name with the correct\n# states.\n\n\nHeader header\n\nstring[] name\nfloat64[] position\nfloat64[] velocity\nfloat64[] effort\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::Joy>
      {

          static const char * value() 
          { 
              return "5a9ea5f83505693b71e785041e67a8bb"; 
          };

          static const uint64_t static_value1 = 0x5a9ea5f83505693bULL;
          static const uint64_t static_value2 = 0x71e785041e67a8bbULL;
      }; // end struct MD5Sum<sensor_msgs::Joy>

      template <> struct DataType<sensor_msgs::Joy>
      {
          static const char * value() { return "sensor_msgs/Joy";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::Joy>
      {
          static const char * value()
          { 
              return "# Reports the state of a joysticks axes and buttons.\nHeader header           # timestamp in the header is the time the data is received from the joystick\nfloat32[] axes          # the axes measurements from a joystick\nint32[] buttons         # the buttons measurements from a joystick \n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::JoyFeedback>
      {

          static const char * value() 
          { 
              return "f4dcd73460360d98f36e55ee7f2e46f1"; 
          };

          static const uint64_t static_value1 = 0xf4dcd73460360d98ULL;
          static const uint64_t static_value2 = 0xf36e55ee7f2e46f1ULL;
      }; // end struct MD5Sum<sensor_msgs::JoyFeedback>

      template <> struct DataType<sensor_msgs::JoyFeedback>
      {
          static const char * value() { return "sensor_msgs/JoyFeedback";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::JoyFeedback>
      {
          static const char * value()
          { 
              return "# Declare of the type of feedback\nuint8 TYPE_LED    = 0\nuint8 TYPE_RUMBLE = 1\nuint8 TYPE_BUZZER = 2\n\nuint8 type\n\n# This will hold an id number for each type of each feedback.\n# Example, the first led would be id=0, the second would be id=1\nuint8 id\n\n# Intensity of the feedback, from 0.0 to 1.0, inclusive.  If device is\n# actually binary, driver should treat 0<=x<0.5 as off, 0.5<=x<=1 as on.\nfloat32 intensity\n\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::JoyFeedbackArray>
      {

          static const char * value() 
          { 
              return "cde5730a895b1fc4dee6f91b754b213d"; 
          };

          static const uint64_t static_value1 = 0xcde5730a895b1fc4ULL;
          static const uint64_t static_value2 = 0xdee6f91b754b213dULL;
      }; // end struct MD5Sum<sensor_msgs::JoyFeedbackArray>

      template <> struct DataType<sensor_msgs::JoyFeedbackArray>
      {
          static const char * value() { return "sensor_msgs/JoyFeedbackArray";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::JoyFeedbackArray>
      {
          static const char * value()
          { 
              return "# This message publishes values for multiple feedback at once. \nJoyFeedback[] array\n================================================================================\nMSG: sensor_msgs/JoyFeedback\n# Declare of the type of feedback\nuint8 TYPE_LED    = 0\nuint8 TYPE_RUMBLE = 1\nuint8 TYPE_BUZZER = 2\n\nuint8 type\n\n# This will hold an id number for each type of each feedback.\n# Example, the first led would be id=0, the second would be id=1\nuint8 id\n\n# Intensity of the feedback, from 0.0 to 1.0, inclusive.  If device is\n# actually binary, driver should treat 0<=x<0.5 as off, 0.5<=x<=1 as on.\nfloat32 intensity\n\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::LaserEcho>
      {

          static const char * value() 
          { 
              return "8bc5ae449b200fba4d552b4225586696"; 
          };

          static const uint64_t static_value1 = 0x8bc5ae449b200fbaULL;
          static const uint64_t static_value2 = 0x4d552b4225586696ULL;
      }; // end struct MD5Sum<sensor_msgs::LaserEcho>

      template <> struct DataType<sensor_msgs::LaserEcho>
      {
          static const char * value() { return "sensor_msgs/LaserEcho";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::LaserEcho>
      {
          static const char * value()
          { 
              return "# This message is a submessage of MultiEchoLaserScan and is not intended\n# to be used separately.\n\nfloat32[] echoes  # Multiple values of ranges or intensities.\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::LaserScan>
      {

          static const char * value() 
          { 
              return "90c7ef2dc6895d81024acba2ac42f369"; 
          };

          static const uint64_t static_value1 = 0x90c7ef2dc6895d81ULL;
          static const uint64_t static_value2 = 0x024acba2ac42f369ULL;
      }; // end struct MD5Sum<sensor_msgs::LaserScan>

      template <> struct DataType<sensor_msgs::LaserScan>
      {
          static const char * value() { return "sensor_msgs/LaserScan";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::LaserScan>
      {
          static const char * value()
          { 
              return "# Single scan from a planar laser range-finder\n#\n# If you have another ranging device with different behavior (e.g. a sonar\n# array), please find or create a different message, since applications\n# will make fairly laser-specific assumptions about this data\n\nHeader header            # timestamp in the header is the acquisition time of \n                         # the first ray in the scan.\n                         #\n                         # in frame frame_id, angles are measured around \n                         # the positive Z axis (counterclockwise, if Z is up)\n                         # with zero angle being forward along the x axis\n                         \nfloat32 angle_min        # start angle of the scan [rad]\nfloat32 angle_max        # end angle of the scan [rad]\nfloat32 angle_increment  # angular distance between measurements [rad]\n\nfloat32 time_increment   # time between measurements [seconds] - if your scanner\n                         # is moving, this will be used in interpolating position\n                         # of 3d points\nfloat32 scan_time        # time between scans [seconds]\n\nfloat32 range_min        # minimum range value [m]\nfloat32 range_max        # maximum range value [m]\n\nfloat32[] ranges         # range data [m] (Note: values < range_min or > range_max should be discarded)\nfloat32[] intensities    # intensity data [device-specific units].  If your\n                         # device does not provide intensities, please leave\n                         # the array empty.\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::MagneticField>
      {

          static const char * value() 
          { 
              return "2f3b0b43eed0c9501de0fa3ff89a45aa"; 
          };

          static const uint64_t static_value1 = 0x2f3b0b43eed0c950ULL;
          static const uint64_t static_value2 = 0x1de0fa3ff89a45aaULL;
      }; // end struct MD5Sum<sensor_msgs::MagneticField>

      template <> struct DataType<sensor_msgs::MagneticField>
      {
          static const char * value() { return "sensor_msgs/MagneticField";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::MagneticField>
      {
          static const char * value()
          { 
              return "# Measurement of the Magnetic Field vector at a specific location.\n\n # If the covariance of the measurement is known, it should be filled in\n # (if all you know is the variance of each measurement, e.g. from the datasheet,\n #just put those along the diagonal)\n # A covariance matrix of all zeros will be interpreted as \"covariance unknown\",\n # and to use the data a covariance will have to be assumed or gotten from some\n # other source\n\n\n Header header                        # timestamp is the time the\n                                      # field was measured\n                                      # frame_id is the location and orientation\n                                      # of the field measurement\n\n geometry_msgs/Vector3 magnetic_field # x, y, and z components of the\n                                      # field vector in Tesla\n                                      # If your sensor does not output 3 axes,\n                                      # put NaNs in the components not reported.\n\n float64[9] magnetic_field_covariance # Row major about x, y, z axes\n                                      # 0 is interpreted as variance unknown\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n\n================================================================================\nMSG: geometry_msgs/Vector3\n# This represents a vector in free space. \n# It is only meant to represent a direction. Therefore, it does not\n# make sense to apply a translation to it (e.g., when applying a \n# generic rigid transformation to a Vector3, tf2 will only apply the\n# rotation). If you want your data to be translatable too, use the\n# geometry_msgs/Point message instead.\n\nfloat64 x\nfloat64 y\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::MultiDOFJointState>
      {

          static const char * value() 
          { 
              return "690f272f0640d2631c305eeb8301e59d"; 
          };

          static const uint64_t static_value1 = 0x690f272f0640d263ULL;
          static const uint64_t static_value2 = 0x1c305eeb8301e59dULL;
      }; // end struct MD5Sum<sensor_msgs::MultiDOFJointState>

      template <> struct DataType<sensor_msgs::MultiDOFJointState>
      {
          static const char * value() { return "sensor_msgs/MultiDOFJointState";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::MultiDOFJointState>
      {
          static const char * value()
          { 
              return "# Representation of state for joints with multiple degrees of freedom, \n# following the structure of JointState.\n#\n# It is assumed that a joint in a system corresponds to a transform that gets applied \n# along the kinematic chain. For example, a planar joint (as in URDF) is 3DOF (x, y, yaw)\n# and those 3DOF can be expressed as a transformation matrix, and that transformation\n# matrix can be converted back to (x, y, yaw)\n#\n# Each joint is uniquely identified by its name\n# The header specifies the time at which the joint states were recorded. All the joint states\n# in one message have to be recorded at the same time.\n#\n# This message consists of a multiple arrays, one for each part of the joint state. \n# The goal is to make each of the fields optional. When e.g. your joints have no\n# wrench associated with them, you can leave the wrench array empty. \n#\n# All arrays in this message should have the same size, or be empty.\n# This is the only way to uniquely associate the joint name with the correct\n# states.\n\nHeader header\n\nstring[] joint_names\ngeometry_msgs/Transform[] transforms\ngeometry_msgs/Twist[] twist\ngeometry_msgs/Wrench[] wrench\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n\n================================================================================\nMSG: geometry_msgs/Transform\n# This represents the transform between two coordinate frames in free space.\n\nVector3 translation\nQuaternion rotation\n\n================================================================================\nMSG: geometry_msgs/Vector3\n# This represents a vector in free space. \n# It is only meant to represent a direction. Therefore, it does not\n# make sense to apply a translation to it (e.g., when applying a \n# generic rigid transformation to a Vector3, tf2 will only apply the\n# rotation). If you want your data to be translatable too, use the\n# geometry_msgs/Point message instead.\n\nfloat64 x\nfloat64 y\nfloat64 z\n================================================================================\nMSG: geometry_msgs/Quaternion\n# This represents an orientation in free space in quaternion form.\n\nfloat64 x\nfloat64 y\nfloat64 z\nfloat64 w\n\n================================================================================\nMSG: geometry_msgs/Twist\n# This expresses velocity in free space broken into its linear and angular parts.\nVector3  linear\nVector3  angular\n\n================================================================================\nMSG: geometry_msgs/Wrench\n# This represents force in free space, separated into\n# its linear and angular parts.\nVector3  force\nVector3  torque\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::MultiEchoLaserScan>
      {

          static const char * value() 
          { 
              return "6fefb0c6da89d7c8abe4b339f5c2f8fb"; 
          };

          static const uint64_t static_value1 = 0x6fefb0c6da89d7c8ULL;
          static const uint64_t static_value2 = 0xabe4b339f5c2f8fbULL;
      }; // end struct MD5Sum<sensor_msgs::MultiEchoLaserScan>

      template <> struct DataType<sensor_msgs::MultiEchoLaserScan>
      {
          static const char * value() { return "sensor_msgs/MultiEchoLaserScan";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::MultiEchoLaserScan>
      {
          static const char * value()
          { 
              return "# Single scan from a multi-echo planar laser range-finder\n#\n# If you have another ranging device with different behavior (e.g. a sonar\n# array), please find or create a different message, since applications\n# will make fairly laser-specific assumptions about this data\n\nHeader header            # timestamp in the header is the acquisition time of \n                         # the first ray in the scan.\n                         #\n                         # in frame frame_id, angles are measured around \n                         # the positive Z axis (counterclockwise, if Z is up)\n                         # with zero angle being forward along the x axis\n                         \nfloat32 angle_min        # start angle of the scan [rad]\nfloat32 angle_max        # end angle of the scan [rad]\nfloat32 angle_increment  # angular distance between measurements [rad]\n\nfloat32 time_increment   # time between measurements [seconds] - if your scanner\n                         # is moving, this will be used in interpolating position\n                         # of 3d points\nfloat32 scan_time        # time between scans [seconds]\n\nfloat32 range_min        # minimum range value [m]\nfloat32 range_max        # maximum range value [m]\n\nLaserEcho[] ranges       # range data [m] (Note: NaNs, values < range_min or > range_max should be discarded)\n                         # +Inf measurements are out of range\n                         # -Inf measurements are too close to determine exact distance.\nLaserEcho[] intensities  # intensity data [device-specific units].  If your\n                         # device does not provide intensities, please leave\n                         # the array empty.\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n\n================================================================================\nMSG: sensor_msgs/LaserEcho\n# This message is a submessage of MultiEchoLaserScan and is not intended\n# to be used separately.\n\nfloat32[] echoes  # Multiple values of ranges or intensities.\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::NavSatFix>
      {

          static const char * value() 
          { 
              return "2d3a8cd499b9b4a0249fb98fd05cfa48"; 
          };

          static const uint64_t static_value1 = 0x2d3a8cd499b9b4a0ULL;
          static const uint64_t static_value2 = 0x249fb98fd05cfa48ULL;
      }; // end struct MD5Sum<sensor_msgs::NavSatFix>

      template <> struct DataType<sensor_msgs::NavSatFix>
      {
          static const char * value() { return "sensor_msgs/NavSatFix";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::NavSatFix>
      {
          static const char * value()
          { 
              return "# Navigation Satellite fix for any Global Navigation Satellite System\n#\n# Specified using the WGS 84 reference ellipsoid\n\n# header.stamp specifies the ROS time for this measurement (the\n#        corresponding satellite time may be reported using the\n#        sensor_msgs/TimeReference message).\n#\n# header.frame_id is the frame of reference reported by the satellite\n#        receiver, usually the location of the antenna.  This is a\n#        Euclidean frame relative to the vehicle, not a reference\n#        ellipsoid.\nHeader header\n\n# satellite fix status information\nNavSatStatus status\n\n# Latitude [degrees]. Positive is north of equator; negative is south.\nfloat64 latitude\n\n# Longitude [degrees]. Positive is east of prime meridian; negative is west.\nfloat64 longitude\n\n# Altitude [m]. Positive is above the WGS 84 ellipsoid\n# (quiet NaN if no altitude is available).\nfloat64 altitude\n\n# Position covariance [m^2] defined relative to a tangential plane\n# through the reported position. The components are East, North, and\n# Up (ENU), in row-major order.\n#\n# Beware: this coordinate system exhibits singularities at the poles.\n\nfloat64[9] position_covariance\n\n# If the covariance of the fix is known, fill it in completely. If the\n# GPS receiver provides the variance of each measurement, put them\n# along the diagonal. If only Dilution of Precision is available,\n# estimate an approximate covariance from that.\n\nuint8 COVARIANCE_TYPE_UNKNOWN = 0\nuint8 COVARIANCE_TYPE_APPROXIMATED = 1\nuint8 COVARIANCE_TYPE_DIAGONAL_KNOWN = 2\nuint8 COVARIANCE_TYPE_KNOWN = 3\n\nuint8 position_covariance_type\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n\n================================================================================\nMSG: sensor_msgs/NavSatStatus\n# Navigation Satellite fix status for any Global Navigation Satellite System\n\n# Whether to output an augmented fix is determined by both the fix\n# type and the last time differential corrections were received.  A\n# fix is valid when status >= STATUS_FIX.\n\nint8 STATUS_NO_FIX =  -1        # unable to fix position\nint8 STATUS_FIX =      0        # unaugmented fix\nint8 STATUS_SBAS_FIX = 1        # with satellite-based augmentation\nint8 STATUS_GBAS_FIX = 2        # with ground-based augmentation\n\nint8 status\n\n# Bits defining which Global Navigation Satellite System signals were\n# used by the receiver.\n\nuint16 SERVICE_GPS =     1\nuint16 SERVICE_GLONASS = 2\nuint16 SERVICE_COMPASS = 4      # includes BeiDou.\nuint16 SERVICE_GALILEO = 8\n\nuint16 service\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::NavSatStatus>
      {

          static const char * value() 
          { 
              return "331cdbddfa4bc96ffc3b9ad98900a54c"; 
          };

          static const uint64_t static_value1 = 0x331cdbddfa4bc96fULL;
          static const uint64_t static_value2 = 0xfc3b9ad98900a54cULL;
      }; // end struct MD5Sum<sensor_msgs::NavSatStatus>

      template <> struct DataType<sensor_msgs::NavSatStatus>
      {
          static const char * value() { return "sensor_msgs/NavSatStatus";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::NavSatStatus>
      {
          static const char * value()
          { 
              return "# Navigation Satellite fix status for any Global Navigation Satellite System\n\n# Whether to output an augmented fix is determined by both the fix\n# type and the last time differential corrections were received.  A\n# fix is valid when status >= STATUS_FIX.\n\nint8 STATUS_NO_FIX =  -1        # unable to fix position\nint8 STATUS_FIX =      0        # unaugmented fix\nint8 STATUS_SBAS_FIX = 1        # with satellite-based augmentation\nint8 STATUS_GBAS_FIX = 2        # with ground-based augmentation\n\nint8 status\n\n# Bits defining which Global Navigation Satellite System signals were\n# used by the receiver.\n\nuint16 SERVICE_GPS =     1\nuint16 SERVICE_GLONASS = 2\nuint16 SERVICE_COMPASS = 4      # includes BeiDou.\nuint16 SERVICE_GALILEO = 8\n\nuint16 service\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::PointCloud>
      {

          static const char * value() 
          { 
              return "d8e9c3f5afbdd8a130fd1d2763945fca"; 
          };

          static const uint64_t static_value1 = 0xd8e9c3f5afbdd8a1ULL;
          static const uint64_t static_value2 = 0x30fd1d2763945fcaULL;
      }; // end struct MD5Sum<sensor_msgs::PointCloud>

      template <> struct DataType<sensor_msgs::PointCloud>
      {
          static const char * value() { return "sensor_msgs/PointCloud";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::PointCloud>
      {
          static const char * value()
          { 
              return "# This message holds a collection of 3d points, plus optional additional\n# information about each point.\n\n# Time of sensor data acquisition, coordinate frame ID.\nHeader header\n\n# Array of 3d points. Each Point32 should be interpreted as a 3d point\n# in the frame given in the header.\ngeometry_msgs/Point32[] points\n\n# Each channel should have the same number of elements as points array,\n# and the data in each channel should correspond 1:1 with each point.\n# Channel names in common practice are listed in ChannelFloat32.msg.\nChannelFloat32[] channels\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n\n================================================================================\nMSG: geometry_msgs/Point32\n# This contains the position of a point in free space(with 32 bits of precision).\n# It is recommeded to use Point wherever possible instead of Point32.  \n# \n# This recommendation is to promote interoperability.  \n#\n# This message is designed to take up less space when sending\n# lots of points at once, as in the case of a PointCloud.  \n\nfloat32 x\nfloat32 y\nfloat32 z\n================================================================================\nMSG: sensor_msgs/ChannelFloat32\n# This message is used by the PointCloud message to hold optional data\n# associated with each point in the cloud. The length of the values\n# array should be the same as the length of the points array in the\n# PointCloud, and each value should be associated with the corresponding\n# point.\n\n# Channel names in existing practice include:\n#   \"u\", \"v\" - row and column (respectively) in the left stereo image.\n#              This is opposite to usual conventions but remains for\n#              historical reasons. The newer PointCloud2 message has no\n#              such problem.\n#   \"rgb\" - For point clouds produced by color stereo cameras. uint8\n#           (R,G,B) values packed into the least significant 24 bits,\n#           in order.\n#   \"intensity\" - laser or pixel intensity.\n#   \"distance\"\n\n# The channel name should give semantics of the channel (e.g.\n# \"intensity\" instead of \"value\").\nstring name\n\n# The values array should be 1-1 with the elements of the associated\n# PointCloud.\nfloat32[] values\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::PointCloud2>
      {

          static const char * value() 
          { 
              return "1158d486dd51d683ce2f1be655c3c181"; 
          };

          static const uint64_t static_value1 = 0x1158d486dd51d683ULL;
          static const uint64_t static_value2 = 0xce2f1be655c3c181ULL;
      }; // end struct MD5Sum<sensor_msgs::PointCloud2>

      template <> struct DataType<sensor_msgs::PointCloud2>
      {
          static const char * value() { return "sensor_msgs/PointCloud2";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::PointCloud2>
      {
          static const char * value()
          { 
              return "# This message holds a collection of N-dimensional points, which may\n# contain additional information such as normals, intensity, etc. The\n# point data is stored as a binary blob, its layout described by the\n# contents of the \"fields\" array.\n\n# The point cloud data may be organized 2d (image-like) or 1d\n# (unordered). Point clouds organized as 2d images may be produced by\n# camera depth sensors such as stereo or time-of-flight.\n\n# Time of sensor data acquisition, and the coordinate frame ID (for 3d\n# points).\nHeader header\n\n# 2D structure of the point cloud. If the cloud is unordered, height is\n# 1 and width is the length of the point cloud.\nuint32 height\nuint32 width\n\n# Describes the channels and their layout in the binary data blob.\nPointField[] fields\n\nbool    is_bigendian # Is this data bigendian?\nuint32  point_step   # Length of a point in bytes\nuint32  row_step     # Length of a row in bytes\nuint8[] data         # Actual point data, size is (row_step*height)\n\nbool is_dense        # True if there are no invalid points\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n\n================================================================================\nMSG: sensor_msgs/PointField\n# This message holds the description of one point entry in the\n# PointCloud2 message format.\nuint8 INT8    = 1\nuint8 UINT8   = 2\nuint8 INT16   = 3\nuint8 UINT16  = 4\nuint8 INT32   = 5\nuint8 UINT32  = 6\nuint8 FLOAT32 = 7\nuint8 FLOAT64 = 8\n\nstring name      # Name of field\nuint32 offset    # Offset from start of point struct\nuint8  datatype  # Datatype enumeration, see above\nuint32 count     # How many elements in the field\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::PointField>
      {

          static const char * value() 
          { 
              return "268eacb2962780ceac86cbd17e328150"; 
          };

          static const uint64_t static_value1 = 0x268eacb2962780ceULL;
          static const uint64_t static_value2 = 0xac86cbd17e328150ULL;
      }; // end struct MD5Sum<sensor_msgs::PointField>

      template <> struct DataType<sensor_msgs::PointField>
      {
          static const char * value() { return "sensor_msgs/PointField";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::PointField>
      {
          static const char * value()
          { 
              return "# This message holds the description of one point entry in the\n# PointCloud2 message format.\nuint8 INT8    = 1\nuint8 UINT8   = 2\nuint8 INT16   = 3\nuint8 UINT16  = 4\nuint8 INT32   = 5\nuint8 UINT32  = 6\nuint8 FLOAT32 = 7\nuint8 FLOAT64 = 8\n\nstring name      # Name of field\nuint32 offset    # Offset from start of point struct\nuint8  datatype  # Datatype enumeration, see above\nuint32 count     # How many elements in the field\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::Range>
      {

          static const char * value() 
          { 
              return "c005c34273dc426c67a020a87bc24148"; 
          };

          static const uint64_t static_value1 = 0xc005c34273dc426cULL;
          static const uint64_t static_value2 = 0x67a020a87bc24148ULL;
      }; // end struct MD5Sum<sensor_msgs::Range>

      template <> struct DataType<sensor_msgs::Range>
      {
          static const char * value() { return "sensor_msgs/Range";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::Range>
      {
          static const char * value()
          { 
              return "# Single range reading from an active ranger that emits energy and reports\n# one range reading that is valid along an arc at the distance measured. \n# This message is  not appropriate for laser scanners. See the LaserScan\n# message if you are working with a laser scanner.\n\n# This message also can represent a fixed-distance (binary) ranger.  This\n# sensor will have min_range===max_range===distance of detection.\n# These sensors follow REP 117 and will output -Inf if the object is detected\n# and +Inf if the object is outside of the detection range.\n\nHeader header           # timestamp in the header is the time the ranger\n                        # returned the distance reading\n\n# Radiation type enums\n# If you want a value added to this list, send an email to the ros-users list\nuint8 ULTRASOUND=0\nuint8 INFRARED=1\n\nuint8 radiation_type    # the type of radiation used by the sensor\n                        # (sound, IR, etc) [enum]\n\nfloat32 field_of_view   # the size of the arc that the distance reading is\n                        # valid for [rad]\n                        # the object causing the range reading may have\n                        # been anywhere within -field_of_view/2 and\n                        # field_of_view/2 at the measured range. \n                        # 0 angle corresponds to the x-axis of the sensor.\n\nfloat32 min_range       # minimum range value [m]\nfloat32 max_range       # maximum range value [m]\n                        # Fixed distance rangers require min_range==max_range\n\nfloat32 range           # range data [m]\n                        # (Note: values < range_min or > range_max\n                        # should be discarded)\n                        # Fixed distance rangers only output -Inf or +Inf.\n                        # -Inf represents a detection within fixed distance.\n                        # (Detection too close to the sensor to quantify)\n                        # +Inf represents no detection within the fixed distance.\n                        # (Object out of range)\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::RegionOfInterest>
      {

          static const char * value() 
          { 
              return "bdb633039d588fcccb441a4d43ccfe09"; 
          };

          static const uint64_t static_value1 = 0xbdb633039d588fccULL;
          static const uint64_t static_value2 = 0xcb441a4d43ccfe09ULL;
      }; // end struct MD5Sum<sensor_msgs::RegionOfInterest>

      template <> struct DataType<sensor_msgs::RegionOfInterest>
      {
          static const char * value() { return "sensor_msgs/RegionOfInterest";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::RegionOfInterest>
      {
          static const char * value()
          { 
              return "# This message is used to specify a region of interest within an image.\n#\n# When used to specify the ROI setting of the camera when the image was\n# taken, the height and width fields should either match the height and\n# width fields for the associated image; or height = width = 0\n# indicates that the full resolution image was captured.\n\nuint32 x_offset  # Leftmost pixel of the ROI\n                 # (0 if the ROI includes the left edge of the image)\nuint32 y_offset  # Topmost pixel of the ROI\n                 # (0 if the ROI includes the top edge of the image)\nuint32 height    # Height of ROI\nuint32 width     # Width of ROI\n\n# True if a distinct rectified ROI should be calculated from the \"raw\"\n# ROI in this message. Typically this should be False if the full image\n# is captured (ROI not used), and True if a subwindow is captured (ROI\n# used).\nbool do_rectify\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::RelativeHumidity>
      {

          static const char * value() 
          { 
              return "8730015b05955b7e992ce29a2678d90f"; 
          };

          static const uint64_t static_value1 = 0x8730015b05955b7eULL;
          static const uint64_t static_value2 = 0x992ce29a2678d90fULL;
      }; // end struct MD5Sum<sensor_msgs::RelativeHumidity>

      template <> struct DataType<sensor_msgs::RelativeHumidity>
      {
          static const char * value() { return "sensor_msgs/RelativeHumidity";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::RelativeHumidity>
      {
          static const char * value()
          { 
              return "# Single reading from a relative humidity sensor.  Defines the ratio of partial\n # pressure of water vapor to the saturated vapor pressure at a temperature.\n\n Header header             # timestamp of the measurement\n                           # frame_id is the location of the humidity sensor\n\n float64 relative_humidity # Expression of the relative humidity\n                           # from 0.0 to 1.0.\n                           # 0.0 is no partial pressure of water vapor\n                           # 1.0 represents partial pressure of saturation\n\n float64 variance          # 0 is interpreted as variance unknown\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::Temperature>
      {

          static const char * value() 
          { 
              return "ff71b307acdbe7c871a5a6d7ed359100"; 
          };

          static const uint64_t static_value1 = 0xff71b307acdbe7c8ULL;
          static const uint64_t static_value2 = 0x71a5a6d7ed359100ULL;
      }; // end struct MD5Sum<sensor_msgs::Temperature>

      template <> struct DataType<sensor_msgs::Temperature>
      {
          static const char * value() { return "sensor_msgs/Temperature";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::Temperature>
      {
          static const char * value()
          { 
              return "# Single temperature reading.\n\n Header header           # timestamp is the time the temperature was measured\n                         # frame_id is the location of the temperature reading\n\n float64 temperature     # Measurement of the Temperature in Degrees Celsius\n\n float64 variance        # 0 is interpreted as variance unknown\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::TimeReference>
      {

          static const char * value() 
          { 
              return "fded64a0265108ba86c3d38fb11c0c16"; 
          };

          static const uint64_t static_value1 = 0xfded64a0265108baULL;
          static const uint64_t static_value2 = 0x86c3d38fb11c0c16ULL;
      }; // end struct MD5Sum<sensor_msgs::TimeReference>

      template <> struct DataType<sensor_msgs::TimeReference>
      {
          static const char * value() { return "sensor_msgs/TimeReference";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::TimeReference>
      {
          static const char * value()
          { 
              return "# Measurement from an external time source not actively synchronized with the system clock.\n\nHeader header    # stamp is system time for which measurement was valid\n                 # frame_id is not used \n\ntime   time_ref  # corresponding time from this external source\nstring source    # (optional) name of time source\n\n================================================================================\nMSG: std_msgs/Header\n# Standard metadata for higher-level stamped data types.\n# This is generally used to communicate timestamped data \n# in a particular coordinate frame.\n# \n# sequence ID: consecutively increasing ID \nuint32 seq\n#Two-integer timestamp that is expressed as:\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n# time-handling sugar is provided by the client library\ntime stamp\n#Frame this data is associated with\n# 0: no frame\n# 1: global frame\nstring frame_id\n";
          };
      };

      template <> struct MD5Sum<sensor_msgs::SetCameraInfoRequest>
      {

          static const char * value() 
          { 
              return "ee34be01fdeee563d0d99cd594d5581d"; 
          };

          static const uint64_t static_value1 = 0xee34be01fdeee563ULL;
          static const uint64_t static_value2 = 0xd0d99cd594d5581dULL;
      }; // end struct MD5Sum<sensor_msgs::SetCameraInfoRequest>

      template <> struct DataType<sensor_msgs::SetCameraInfoRequest>
      {
          static const char * value() { return "sensor_msgs/SetCameraInfoRequest";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::SetCameraInfoRequest>
      {
          static const char * value()
          { 
              return sensor_msgs::SetCameraInfoRequest::XML_SOURCE.c_str();
          };
      };

      template <> struct MD5Sum<sensor_msgs::SetCameraInfoResponse>
      {

          static const char * value() 
          { 
              return "2ec6f3eff0161f4257b808b12bc830c2"; 
          };

          static const uint64_t static_value1 = 0x2ec6f3eff0161f42ULL;
          static const uint64_t static_value2 = 0x57b808b12bc830c2ULL;
      }; // end struct MD5Sum<sensor_msgs::SetCameraInfoResponse>

      template <> struct DataType<sensor_msgs::SetCameraInfoResponse>
      {
          static const char * value() { return "sensor_msgs/SetCameraInfoResponse";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::SetCameraInfoResponse>
      {
          static const char * value()
          { 
              return sensor_msgs::SetCameraInfoResponse::XML_SOURCE.c_str();
          };
      };

      template <> struct MD5Sum<sensor_msgs::SetCameraInfo>
      {

          static const char * value() 
          { 
              return "d41d8cd98f00b204e9800998ecf8427e"; 
          };

          static const uint64_t static_value1 = 0xd41d8cd98f00b204ULL;
          static const uint64_t static_value2 = 0xe9800998ecf8427eULL;
      }; // end struct MD5Sum<sensor_msgs::SetCameraInfo>

      template <> struct DataType<sensor_msgs::SetCameraInfo>
      {
          static const char * value() { return "sensor_msgs/SetCameraInfo";};
      }; // end DataType

      template <> struct Definition<sensor_msgs::SetCameraInfo>
      {
          static const char * value()
          { 
              return sensor_msgs::SetCameraInfo::XML_SOURCE.c_str();
          };
      };

  }; // end namespace message_traits

}; // namespace ros

#endif // _CODEGEN_SENSOR_MSGS_GENCPP_ROS_H_

