// 
//  AUTOGENERATED FILE:   do not edit
//
//  Generated by:         alex on alex-laptop, 2016-11-23 12:44:57 -0500
//  From Template/Script: data_templates/DataClassTemplate.cpp
 
/*
  CTA RIGHTS

  This document contains information proprietary to General Dynamics
  Robotic Systems and is not to be reproduced, transmitted, transferred,
  or otherwise used without the express written consent of General
  Dynamics Robotic Systems except as described below.

  GOVERNMENT PURPOSE RIGHTS

  Contract No.:        W911NF-10-2-0016, Articles of Collaboration,
                       Article 5, Intellectual Property
  Contractor Name:     General Dynamics Robotic Systems, Inc. (GDRS)
  Contractor Address:  1231 Tech Court, Westminster, MD  21157

  Expiration Date - None

  Technical data and computer software first created by Member(s) in
  performance of the Agreement will be disclosed to the Government.
  General Dynamics Robotic Systems retains the entire right, title, and
  interest throughout the world to each subject invention subject to the
  provisions of this clause and 37 CFR Part 401, 32 CFR 32.36, and
  34 CFR 34.25. The Government shall have the right to obtain, reproduce,
  publish or otherwise use the work for Government purposes.

  NON-EXCLUSIVE LICENSE TO CONSORTIUM PARTICIPANTS
  Consortium Members and subawardees are defined as 'Participants'
  Under Article 5.3, Participants are granted a nonexclusive, royalty-
  free, non-sublicenseable, non-assignable, license to Consortium
  Intellectual Property for the limited purpose of performing tasks under
  The Cooperative Agreement, for Government purposes only, and to make and
  have the same made solely for such use.

*/

#include <math.h> // to allow use of common constants...
#include <common/Error.h>
#include "stereo_msgs/DisparityImage.h"

#include <common/JsonIo.h> // include here so container types are included by the class header 

using namespace std;

const unsigned int stereo_msgs::DisparityImage::ID;
const unsigned int stereo_msgs::DisparityImage::DATA_VERSION;
const std::string stereo_msgs::DisparityImage::DATA_TYPE_NAME = "DisparityImage";
const std::string stereo_msgs::DisparityImage::DATA_TYPE_FULL_NAME = "stereo_msgs::DisparityImage";
const std::string stereo_msgs::DisparityImage::VERSION_MD5 = "781afc80285e5a407737b7595f5e8d11";
/* xml source for this class */
const std::string stereo_msgs::DisparityImage::XML_SOURCE = "<class name=\"DisparityImage\" publicDataMembers=\"true\" sourceIDL=\"ROS\" ros=\"true\" rosMD5=\"04a177815f75271039fa21f16acad8c9\" rosDesc=\"# Separate header for compatibility with current TimeSynchronizer.\\n# Likely to be removed in a later release, use image.header instead.\\nHeader header\\n\\n# Floating point disparity image. The disparities are pre-adjusted for any\\n# x-offset between the principal points of the two cameras (in the case\\n# that they are verged). That is: d = x_l - x_r - (cx_l - cx_r)\\nsensor_msgs/Image image\\n\\n# Stereo geometry. For disparity d, the depth from the camera is Z = fT/d.\\nfloat32 f # Focal length, pixels\\nfloat32 T # Baseline, world units\\n\\n# Subwindow of (potentially) valid disparity values.\\nsensor_msgs/RegionOfInterest valid_window\\n\\n# The range of disparities searched.\\n# In the disparity image, any disparity less than min_disparity is invalid.\\n# The disparity search range defines the horopter, or 3D volume that the\\n# stereo algorithm can \\&quot;see\\&quot;. Points with Z outside of:\\n#     Z_min = fT / max_disparity\\n#     Z_max = fT / min_disparity\\n# could not be found.\\nfloat32 min_disparity\\nfloat32 max_disparity\\n\\n# Smallest allowed disparity increment. The smallest achievable depth range\\n# resolution is delta_Z = (Z^2/fT)*delta_d.\\nfloat32 delta_d\\n\\n================================================================================\\nMSG: std_msgs/Header\\n# Standard metadata for higher-level stamped data types.\\n# This is generally used to communicate timestamped data \\n# in a particular coordinate frame.\\n# \\n# sequence ID: consecutively increasing ID \\nuint32 seq\\n#Two-integer timestamp that is expressed as:\\n# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\\n# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\\n# time-handling sugar is provided by the client library\\ntime stamp\\n#Frame this data is associated with\\n# 0: no frame\\n# 1: global frame\\nstring frame_id\\n\\n================================================================================\\nMSG: sensor_msgs/Image\\n# This message contains an uncompressed image\\n# (0, 0) is at top-left corner of image\\n#\\n\\nHeader header        # Header timestamp should be acquisition time of image\\n                     # Header frame_id should be optical frame of camera\\n                     # origin of frame should be optical center of cameara\\n                     # +x should point to the right in the image\\n                     # +y should point down in the image\\n                     # +z should point into to plane of the image\\n                     # If the frame_id here and the frame_id of the CameraInfo\\n                     # message associated with the image conflict\\n                     # the behavior is undefined\\n\\nuint32 height         # image height, that is, number of rows\\nuint32 width          # image width, that is, number of columns\\n\\n# The legal values for encoding are in file src/image_encodings.cpp\\n# If you want to standardize a new string format, join\\n# ros-users@lists.sourceforge.net and send an email proposing a new encoding.\\n\\nstring encoding       # Encoding of pixels -- channel meaning, ordering, size\\n                      # taken from the list of strings in include/sensor_msgs/image_encodings.h\\n\\nuint8 is_bigendian    # is this data bigendian?\\nuint32 step           # Full row length in bytes\\nuint8[] data          # actual matrix data, size is (step * rows)\\n\\n================================================================================\\nMSG: sensor_msgs/RegionOfInterest\\n# This message is used to specify a region of interest within an image.\\n#\\n# When used to specify the ROI setting of the camera when the image was\\n# taken, the height and width fields should either match the height and\\n# width fields for the associated image; or height = width = 0\\n# indicates that the full resolution image was captured.\\n\\nuint32 x_offset  # Leftmost pixel of the ROI\\n                 # (0 if the ROI includes the left edge of the image)\\nuint32 y_offset  # Topmost pixel of the ROI\\n                 # (0 if the ROI includes the top edge of the image)\\nuint32 height    # Height of ROI\\nuint32 width     # Width of ROI\\n\\n# True if a distinct rectified ROI should be calculated from the \\&quot;raw\\&quot;\\n# ROI in this message. Typically this should be False if the full image\\n# is captured (ROI not used), and True if a subwindow is captured (ROI\\n# used).\\nbool do_rectify\\n\" comment=\"Separate header for compatibility with current TimeSynchronizer.  Likely to be removed in a later release, use image.header instead.\" id=\"2048171948\">\
  <field name=\"header\" type=\"std_msgs::Header\" sourceType=\"Header\" comment=\"Floating point disparity image. The disparities are pre-adjusted for any  x-offset between the principal points of the two cameras (in the case  that they are verged). That is: d = x_l - x_r - (cx_l - cx_r)\"/>\
  <field name=\"image\" type=\"sensor_msgs::Image\" sourceType=\"sensor_msgs::Image\" comment=\"Stereo geometry. For disparity d, the depth from the camera is Z = fT/d.\"/>\
  <field name=\"f\" type=\"float\" sourceType=\"float32\" comment=\"Focal length, pixels\"/>\
  <field name=\"T\" type=\"float\" sourceType=\"float32\" comment=\"Baseline, world units  Subwindow of (potentially) valid disparity values.\"/>\
  <field name=\"valid_window\" type=\"sensor_msgs::RegionOfInterest\" sourceType=\"sensor_msgs::RegionOfInterest\" comment=\"The range of disparities searched.  In the disparity image, any disparity less than min_disparity is invalid.  The disparity search range defines the horopter, or 3D volume that the  stereo algorithm can &quot;see&quot;. Points with Z outside of:      Z_min = fT / max_disparity      Z_max = fT / min_disparity  could not be found.\"/>\
  <field name=\"min_disparity\" type=\"float\" sourceType=\"float32\" comment=\"\"/>\
  <field name=\"max_disparity\" type=\"float\" sourceType=\"float32\" comment=\"Smallest allowed disparity increment. The smallest achievable depth range  resolution is delta_Z = (Z^2/fT)*delta_d.\"/>\
  <field name=\"delta_d\" type=\"float\" sourceType=\"float32\" comment=\"\"/>\
</class>";

stereo_msgs::DisparityImage::DisparityImage() : header(), image(), f(0), T(0), valid_window(), min_disparity(0), max_disparity(0), delta_d(0)
{  
};

stereo_msgs::DisparityImage::DisparityImage(const stereo_msgs::DisparityImage & inobj) : header(inobj.header), image(inobj.image), f(inobj.f), T(inobj.T), valid_window(inobj.valid_window), min_disparity(inobj.min_disparity), max_disparity(inobj.max_disparity), delta_d(inobj.delta_d)
{
};

stereo_msgs::DisparityImage::~DisparityImage()
{
};

stereo_msgs::DisparityImage * stereo_msgs::DisparityImage::New()
{ 
    return new DisparityImage();
};

bool stereo_msgs::DisparityImage::dataTypeFlat() 
{  
    return std_msgs::Header::dataTypeFlat() && sensor_msgs::Image::dataTypeFlat() && sensor_msgs::RegionOfInterest::dataTypeFlat();

};

stereo_msgs::DisparityImage & stereo_msgs::DisparityImage::operator=(const stereo_msgs::DisparityImage & inobj)
{
    if (this != &inobj)
    {

        // if datatype is flat, optimize with memcpy (complier level optimiation)
              /*  if (dataTypeFlat() == true)
                  REMOVED invalid when assigning from a parent type as this is the pointer to the derived type, thus stereo_msgs::DisparityImage is copied to the wrong location

        {
            memcpy(this,&inobj,sizeof(stereo_msgs::DisparityImage));
        }
        else */ 
        {

            header = inobj.header;
            image = inobj.image;
            f = inobj.f;
            T = inobj.T;
            valid_window = inobj.valid_window;
            min_disparity = inobj.min_disparity;
            max_disparity = inobj.max_disparity;
            delta_d = inobj.delta_d;
        }
    }

    return *this;
}

bool stereo_msgs::DisparityImage::operator==(const stereo_msgs::DisparityImage & inobj) const
{
    bool ret = true;

    if (this != &inobj)
    { 
        ret = ret 
             && (header == inobj.header)
             && (image == inobj.image)
             && (f == inobj.f)
             && (T == inobj.T)
             && (valid_window == inobj.valid_window)
             && (min_disparity == inobj.min_disparity)
             && (max_disparity == inobj.max_disparity)
             && (delta_d == inobj.delta_d);
    }

    return ret;
}

bool stereo_msgs::DisparityImage::operator!=(const stereo_msgs::DisparityImage & inobj) const
{
    bool ret = false;

    if (this != &inobj)
    {
        ret = !operator==(inobj);
    }

    return ret;
}

bool stereo_msgs::DisparityImage::operator<(const stereo_msgs::DisparityImage & inobj) const
{
    bool ret = false;

    if (this == &inobj)
    {
        ret = false;
    }
    else
    {  
        // comparison algorithm based on std::lexicographical_compare algorithm

        if (header < inobj.header) return true;
        if (inobj.header <  header) return false; 
        if (image < inobj.image) return true;
        if (inobj.image <  image) return false; 
        if (f < inobj.f) return true;
        if (inobj.f <  f) return false; 
        if (T < inobj.T) return true;
        if (inobj.T <  T) return false; 
        if (valid_window < inobj.valid_window) return true;
        if (inobj.valid_window <  valid_window) return false; 
        if (min_disparity < inobj.min_disparity) return true;
        if (inobj.min_disparity <  min_disparity) return false; 
        if (max_disparity < inobj.max_disparity) return true;
        if (inobj.max_disparity <  max_disparity) return false; 
        if (delta_d < inobj.delta_d) return true;
        if (inobj.delta_d <  delta_d) return false; ;
    }

    return ret;
}

bool stereo_msgs::DisparityImage::operator>(const stereo_msgs::DisparityImage & inobj) const
{
    bool ret = false;

    if (this == &inobj)
    {
        ret = false;
    }
    else
    {
        // comparison algorithm based on std::lexicographical_compare algorithm

        if (header > inobj.header) return true;
        if (inobj.header >  header) return false; 
        if (image > inobj.image) return true;
        if (inobj.image >  image) return false; 
        if (f > inobj.f) return true;
        if (inobj.f >  f) return false; 
        if (T > inobj.T) return true;
        if (inobj.T >  T) return false; 
        if (valid_window > inobj.valid_window) return true;
        if (inobj.valid_window >  valid_window) return false; 
        if (min_disparity > inobj.min_disparity) return true;
        if (inobj.min_disparity >  min_disparity) return false; 
        if (max_disparity > inobj.max_disparity) return true;
        if (inobj.max_disparity >  max_disparity) return false; 
        if (delta_d > inobj.delta_d) return true;
        if (inobj.delta_d >  delta_d) return false; ;
    }

    return ret;
}

template <> void rframe::json_io::encode(std::stringstream & sstr, const char * name, const stereo_msgs::DisparityImage & t, std::string & indent, bool lastItem)
{
    if ((name) && (*name != '\0')) rframe::json_io::encodeObjectStart(sstr,name,indent);

    rframe::json_io::encode(sstr,"header",t.header,indent,false);
    rframe::json_io::encode(sstr,"image",t.image,indent,false);
    rframe::json_io::encode(sstr,"f",t.f,indent,false);
    rframe::json_io::encode(sstr,"T",t.T,indent,false);
    rframe::json_io::encode(sstr,"valid_window",t.valid_window,indent,false);
    rframe::json_io::encode(sstr,"min_disparity",t.min_disparity,indent,false);
    rframe::json_io::encode(sstr,"max_disparity",t.max_disparity,indent,false);
    rframe::json_io::encode(sstr,"delta_d",t.delta_d,indent,true);

    if ((name) && (*name != '\0')) rframe::json_io::encodeObjectEnd(sstr,indent,lastItem);
}

std::string stereo_msgs::DisparityImage::toStr(bool pretty) const
{

    stringstream sstr;
    string indent = (pretty == true) ? "\n" : "";

    rframe::json_io::encodeObjectStartMain(sstr,indent);
    rframe::json_io::encode(sstr,"",*this,indent,true);
    rframe::json_io::encodeObjectEnd(sstr,indent,true); // false so as to  not add , at end of string

    return sstr.str();

};

std::basic_ostream<char>& operator<<(std::basic_ostream<char> &s, const stereo_msgs::DisparityImage & value)
{
    return s << value.toStr(false);
}

